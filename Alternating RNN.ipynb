{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/perceval/anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/perceval/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=80, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCUSSIONS_COUNT = 10\n",
    "DISCUSSION_LENGTH = 32\n",
    "TARGETS_COUNT = 16\n",
    "EMBEDDING_DIM = 32,\n",
    "LSTM_UNITS_COUNT = 32,\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_pairs = np.array([np.random.choice(TARGETS_COUNT, 2, replace=False) for _ in range(DISCUSSIONS_COUNT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = np.zeros((DISCUSSIONS_COUNT, DISCUSSION_LENGTH, TARGETS_COUNT))\n",
    "\n",
    "# get a hint in the first utterance about the first speaker\n",
    "input_matrix[np.arange(DISCUSSIONS_COUNT), 0, targets_pairs[:, 0]] = 1\n",
    "input_matrix[np.arange(DISCUSSIONS_COUNT), 1, targets_pairs[:, 1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_matrix = np.zeros((DISCUSSIONS_COUNT, DISCUSSION_LENGTH, TARGETS_COUNT))\n",
    "for i in range(DISCUSSION_LENGTH//2):\n",
    "    output_matrix[np.arange(DISCUSSIONS_COUNT), i*2, targets_pairs[:, 0]] = 1\n",
    "    output_matrix[np.arange(DISCUSSIONS_COUNT), i*2+1, targets_pairs[:, 1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=(None, TARGETS_COUNT)) # leave the dataset length that will be batched\n",
    "\n",
    "people_hint_bag_layer = keras.layers.Dense(params[\"EMBEDDING_DIM\"], activation='relu')\n",
    "\n",
    "lstm_input = people_hint_bag_layer(input_layer)#keras.layers.Activation('relu')(concat_input)\n",
    "\n",
    "# not mandatory to set the LSTM dim output to the people hints dim input but it seems more coherent\n",
    "\n",
    "lstm_layer = keras.layers.GRU(params['LSTM_UNITS_COUNT'], return_sequences=True)\n",
    "lstm_output = lstm_layer(lstm_input)\n",
    "\n",
    "output_layer = keras.layers.Dense(TARGETS_COUNT, activation='softmax')\n",
    "#lstm_layer = keras.layers.Dense(len(people)+1, activation='softmax')\n",
    "output = output_layer(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs = input_layer, outputs = [output])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 139ms/step\n",
      "[0.8963462710380554, 0.5218750238418579]\n",
      "10/10 [==============================] - 0s 860us/step\n",
      "[0.26403096318244934, 0.918749988079071]\n",
      "10/10 [==============================] - 0s 654us/step\n",
      "[0.0444922149181366, 1.0]\n",
      "10/10 [==============================] - 0s 670us/step\n",
      "[0.01800515502691269, 1.0]\n",
      "10/10 [==============================] - 0s 802us/step\n",
      "[0.008890574797987938, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# WITH EMBEDDING_DIM=32, LSTM = 32, N=16\n",
    "\n",
    "for i in range(5):\n",
    "    model.fit(input_matrix, output_matrix, epochs=1000, verbose=0)\n",
    "    print(model.evaluate(input_matrix, output_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 112ms/step\n",
      "[0.6733682751655579, 0.53125]\n",
      "10/10 [==============================] - 0s 767us/step\n",
      "[0.3160506784915924, 0.831250011920929]\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "[0.1443367600440979, 0.8999999761581421]\n",
      "10/10 [==============================] - 0s 689us/step\n",
      "[0.13329936563968658, 0.90625]\n",
      "10/10 [==============================] - 0s 723us/step\n",
      "[0.004640371073037386, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# WITH EMBEDDING_DIM=32, LSTM = 32, N=8\n",
    "\n",
    "for i in range(5):\n",
    "    model.fit(input_matrix, output_matrix, epochs=2000, verbose=0)\n",
    "    print(model.evaluate(input_matrix, output_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 125ms/step\n",
      "[0.7263706922531128, 0.5249999761581421]\n",
      "10/10 [==============================] - 0s 770us/step\n",
      "[0.6546169519424438, 0.5625]\n",
      "10/10 [==============================] - 0s 661us/step\n",
      "[0.6356932520866394, 0.546875]\n",
      "10/10 [==============================] - 0s 681us/step\n",
      "[0.5890239477157593, 0.6343749761581421]\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "[0.4870223104953766, 0.6625000238418579]\n"
     ]
    }
   ],
   "source": [
    "# WITH LSTM=64, N=8\n",
    "\n",
    "for i in range(5):\n",
    "    model.fit(input_matrix, output_matrix, epochs=2000, verbose=0)\n",
    "    print(model.evaluate(input_matrix, output_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 108ms/step\n",
      "[0.6815983057022095, 0.515625]\n",
      "10/10 [==============================] - 0s 671us/step\n",
      "[0.31143176555633545, 0.796875]\n",
      "10/10 [==============================] - 0s 704us/step\n",
      "[0.1881525218486786, 0.875]\n",
      "10/10 [==============================] - 0s 665us/step\n",
      "[0.12290861457586288, 0.9375]\n",
      "10/10 [==============================] - 0s 617us/step\n",
      "[0.06663595139980316, 0.9593750238418579]\n"
     ]
    }
   ],
   "source": [
    "# WITH LSTM=32, N=8\n",
    "\n",
    "for i in range(5):\n",
    "    model.fit(input_matrix, output_matrix, ecpochs=2000, verbose=0)\n",
    "    print(model.evaluate(input_matrix, output_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6507 - acc: 0.5531\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6507 - acc: 0.5531\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6507 - acc: 0.5531\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6507 - acc: 0.5531\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6507 - acc: 0.5531\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6507 - acc: 0.5531\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6506 - acc: 0.5531\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6506 - acc: 0.5531\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6506 - acc: 0.5531\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6506 - acc: 0.5531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cc86b00>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_matrix, output_matrix, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cc86828>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_matrix, output_matrix, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2569 - acc: 0.8531\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2568 - acc: 0.8500\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2567 - acc: 0.8500\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2566 - acc: 0.8531\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2564 - acc: 0.8531\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2563 - acc: 0.8531\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2562 - acc: 0.8531\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2561 - acc: 0.8531\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2559 - acc: 0.8500\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2558 - acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d6dbba8>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_matrix, output_matrix, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d6dbbe0>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_matrix, output_matrix, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d6dba90>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_matrix, output_matrix, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.9148e-07, 1.2005e-03, 6.7917e-07, ..., 2.1546e-05, 2.2659e-06,\n",
       "         3.2168e-08],\n",
       "        [1.7155e-05, 1.7705e-03, 1.0621e-05, ..., 1.2168e-05, 4.3264e-06,\n",
       "         2.2561e-04],\n",
       "        [4.4368e-06, 4.4145e-04, 4.6635e-06, ..., 1.8069e-08, 2.8505e-06,\n",
       "         3.3394e-03],\n",
       "        ...,\n",
       "        [2.1087e-05, 1.8694e-03, 1.2891e-05, ..., 1.4140e-05, 5.0801e-06,\n",
       "         2.7778e-04],\n",
       "        [4.8591e-06, 4.3603e-04, 5.1810e-06, ..., 2.2618e-08, 3.0554e-06,\n",
       "         3.2629e-03],\n",
       "        [2.1087e-05, 1.8694e-03, 1.2891e-05, ..., 1.4140e-05, 5.0801e-06,\n",
       "         2.7778e-04]]], dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1087e-05, 1.8694e-03, 1.2891e-05, 5.8751e-04, 9.8956e-01, 6.5572e-06,\n",
       "       1.0620e-06, 6.7972e-03, 1.9439e-06, 7.1675e-04, 1.2168e-04, 5.9335e-09,\n",
       "       1.1342e-05, 1.4140e-05, 5.0801e-06, 2.7778e-04], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
