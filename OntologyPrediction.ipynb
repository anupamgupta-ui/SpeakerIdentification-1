{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "%aimport prolog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Extract people... ?\n",
    "# \n",
    "# from interval import interval\n",
    "# \n",
    "# text = \" \".join(s[\"source\"] for s in dataset)\n",
    "# \n",
    "# # Find Cap names\n",
    "# cap_names = list(re.finditer(\"(?:[a-z][,:; ]+)([A-Z][a-z]*(?:\\s+[A-Z][a-z]*)*)\", text))\n",
    "# # Find Mr., Mrs., Sir. names\n",
    "# title_names = list(re.finditer(\"([Mm](?:rs?\\.?|iss\\.?|[Ss]ir)\\s+[A-Z][a-z]*(?:\\s+[A-Z][a-z]*)*)\", text))\n",
    "# \n",
    "# characters_spans = interval(*[n.span(1) for n in cap_names] + [n.span(0) for n in title_names])\n",
    "# \n",
    "# # {text[int(s[0]):int(s[1])]: ((int(s[0]), int(s[1]), text[int(s[0])-10:int(s[1])+20])) for s in characters_spans}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we just hard code the known list of protagonists (corrected from the given list in the article)\n",
    "\n",
    "`people_list = [...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_list = pickle.load(open(\"corpus/people.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_code_to_name = {p[\"code\"]: p[\"main\"] for p in people_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book utterances splitting and annotations matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Almost match :\n",
      "My dear Elizabeth_Bennet, I have the highest opinion in the world of your excellent judgment in all matters within the scope of your understanding, but permit me to say that there must be a wide difference between the established forms of ceremony amongst the laity, and those which regulate the clergy; for give me leave to observe that I consider the clerical office as equal in point of dignity with the highest rank in the kingdom -- provided that a proper humility of behaviour is at the same time maintained. You must therefore allow me to follow the dictates of my conscience on this occasion, which leads me to perform what I look on as a point of duty. Pardon me for neglecting to profit by your advice, which on every other subject shall be my constant guide, though in the case before us I consider myself more fitted by education and habitual study to decide on what is right than a young lady like yourself. [X] apology, [X] Hunsford, [X] Lady_Catherine.\n",
      "My dear Elizabeth_Bennet, I have the highest opinion in the world of your excellent judgment in all matters within the scope of your understanding, but permit me to say that there must be a wide difference between the established forms of ceremony amongst the laity, and those which regulate the clergy; for give me leave to observe that I consider the clerical office as equal in point of dignity with the highest rank in the kingdom -- provided that a proper humility of behaviour is at the same time maintained. You must therefore allow me to follow the dictates of my conscience on this occasion, which leads me to perform what I look on as a point of duty. Pardon me for neglecting to profit by your advice, which on every other subject shall be my constant guide, though in the case before us I consider myself more fitted by education and habitual study to decide on what is right than a young lady like yourself. apology, Hunsford, Lady_Catherine.\n",
      "--\n",
      "Almost match :\n",
      "delightful, [X] charming,\n",
      "delightful, charming,\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "utterances = preprocessing.build_dataset(\n",
    "    text_file='corpus/PRIDPREJ_NONEWLINE_Organize_v2.txt',\n",
    "    people=people_list\n",
    ")\n",
    "dataset = preprocessing.match_with_annoted_file(\n",
    "    path='corpus/REAL_ALL_CONTENTS_PP.txt',\n",
    "    utterances=utterances,\n",
    "    people=people_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'begin': 0,\n",
       " 'discussion_index': 0,\n",
       " 'end': 109,\n",
       " 'only_utterance_article': 'My dear Mr_Bennet, [X] have you heard that Netherfield Park is let at last?',\n",
       " 'only_utterance_us': 'My dear Mr_Bennet, [X] have you heard that Netherfield Park is let at last?',\n",
       " 'parts': [{'text': 'My dear Mr_Bennet,', 'utterance': True},\n",
       "  {'text': ' said his lady to him one day, ', 'utterance': False},\n",
       "  {'text': 'have you heard that Netherfield Park is let at last?',\n",
       "   'utterance': True}],\n",
       " 'source': \"``My dear Mr_Bennet,'' said his lady to him one day, ``have you heard that Netherfield Park is let at last?''\",\n",
       " 'target': 'Mrs_Bennet'}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammar parsing\n",
    "\n",
    "Let's detect the gender/role/name features in the narration parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.parse import stanford\n",
    "\n",
    "jar = '../stanford-parser-full-2017-06-09/stanford-parser.jar'\n",
    "model = '../stanford-parser-full-2017-06-09/stanford-parser-3.8.0-models.jar'\n",
    "\n",
    "dep_parser = stanford.StanfordDependencyParser(model, jar, model_path='edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add standford parser annotations like name or gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1302/1302 [41:05<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Stanford parser rules: triples -> name, gender, etc #\n",
    "#######################################################\n",
    "def extract_features(triple):\n",
    "    (word1, tag1), dep, (word2, tag2) = triple\n",
    "    if (tag1.startswith('VBD') or word1 in ['said', 'added', 'cried', 'asked', 'replied', 'returned', 'continued', 'observed']) and (tag2.startswith('NN') or tag2.startswith('PRP')) and not dep.startswith('nmod'):\n",
    "        if tag2.startswith('NN'):\n",
    "            if tag2.startswith('NNP'):\n",
    "                speaker_name = word2\n",
    "            else:\n",
    "                speaker_role = word2\n",
    "        if word2 in ['he', 'man', 'boy', 'lad']:\n",
    "            speaker_gender = 'M'\n",
    "        if word2 in ['she', 'lady', 'girl']:\n",
    "            speaker_gender = 'F'\n",
    "    return (speaker_name, speaker_role, speaker_gender)\n",
    "\n",
    "\n",
    "for sample in tqdm.tqdm(dataset):\n",
    "    for part in sample[\"parts\"]:\n",
    "        if not part[\"utterance\"]:\n",
    "            speaker_name = None\n",
    "            speaker_role = None\n",
    "            speaker_gender = None\n",
    "            tokens = nltk.word_tokenize(re.sub(\"[^_\\w]\", \"\", part[\"text\"][:200]))\n",
    "            tagged = nltk.pos_tag(tokens)\n",
    "            try:\n",
    "                dependencies = sum([[list(parse.triples()) for parse in dep_graphs] for dep_graphs in dep_parser.tagged_parse_sents([tagged])],[])\n",
    "                for (term1,dep,term2) in dependencies[0]:\n",
    "                    #print(term1, dep, term2)\n",
    "                    speaker_name, speaker_role, speaker_gender = extract_features((term1,dep,term2) )\n",
    "                    # try reverse order\n",
    "                    speaker_name, speaker_role, speaker_gender =  extract_features((term2,dep,term1) )\n",
    "            except Exception as e:\n",
    "                    print(e)\n",
    "                    print(part)\n",
    "            part[\"speaker_name\"] = speaker_name\n",
    "            part[\"speaker_role\"] = speaker_role\n",
    "            part[\"speaker_gender\"] = speaker_gender\n",
    "            #print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dataset, open(\"corpus/dataset-parser-features.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_roles = {\n",
    "    \"husband\": \"husband\",\n",
    "    \"lady\": \"wife\",\n",
    "    \"wife\": \"wife\",\n",
    "    \"aunt\": \"aunt\",\n",
    "    \"uncle\": \"uncle\",\n",
    "    \"father\": \"father\",\n",
    "    \"sister\": \"sister\",\n",
    "    \"mother\": \"mother\",\n",
    "    \"daughter\": \"daughter\",\n",
    "    \"son\": \"son\",\n",
    "    \"cousin\": \"cousin\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Prolog engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define facts\n",
    "\n",
    "`facts = [...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = \"\"\"\n",
    "status(mrs_annesley,female).\n",
    "status(elizabeth_bennet,female).\n",
    "status(jane_bennet,female).\n",
    "status(lydia_bennet,female).\n",
    "status(kitty_bennet,female).\n",
    "status(mary_bennet,female).\n",
    "status(mrs_bennet,female).\n",
    "status(mr_bennet,male).\n",
    "status(mr_bingley,male).\n",
    "status(caroline_bingley,female).\n",
    "status(charlotte,female).\n",
    "status(captain_carter,female).\n",
    "status(mr_collins,male).\n",
    "status(lady_catherine,female).\n",
    "status(mr_chamberlayne,female).\n",
    "status(dawson,female).\n",
    "status(mr_denny,female).\n",
    "status(mr_darcy,male).\n",
    "status(old_mr_darcy,female).\n",
    "status(lady_anne_darcy,female).\n",
    "status(georgiana_darcy,female).\n",
    "status(colonel_fitzwilliam,male).\n",
    "status(colonel_forster,female).\n",
    "status(miss_grantley,female).\n",
    "status(mrs_gardiner,female).\n",
    "status(mr_gardiner,male).\n",
    "status(william_goulding,female).\n",
    "status(haggerston,female).\n",
    "status(mrs_hill,female).\n",
    "status(mrs_jenkinson,female).\n",
    "status(mr_jones,female).\n",
    "status(miss_mary_king,female).\n",
    "status(mrs_long,female).\n",
    "status(lady_lucas,female).\n",
    "status(maria_lucas,female).\n",
    "status(mr_hurst,female).\n",
    "status(louisa_hurst,female).\n",
    "status(lady_metcalfe,female).\n",
    "status(mr_morris,female).\n",
    "status(mrs_nicholls,female).\n",
    "status(mr_philips,male).\n",
    "status(miss_pope,female).\n",
    "status(mr_pratt,male).\n",
    "status(mrs_reynolds,female).\n",
    "status(mr_robinson,female).\n",
    "status(mr_stone,female).\n",
    "status(miss_watson,female).\n",
    "status(old_mr_wickham,female).\n",
    "status(sir_william,male).\n",
    "status(anne_de_bourgh,female).\n",
    "status(mr_wickham,male).\n",
    "status(mrs_philips,female).\n",
    "status(young_lucas,male).\n",
    "status(the_butler,male).\n",
    "\n",
    "status(elizabeth_bennet,female).\n",
    "related(jane_bennet,elizabeth_bennet,sister).\n",
    "related(mary_bennet,elizabeth_bennet,sister).\n",
    "related(lydia_bennet,elizabeth_bennet,sister).\n",
    "related(kitty_bennet,elizabeth_bennet,sister).\n",
    "related(mr_bennet,elizabeth_bennet,father).\n",
    "related(mrs_bennet,elizabeth_bennet,mother).\n",
    "related(mr_collins,charlotte,husband).\n",
    "related(mr_collins,mr_bennet,brother).\n",
    "related(mr_bingley,caroline_bingley,siblings).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"prolog_engine\" in globals() and not prolog_engine.closed:\n",
    "    prolog_engine.close()\n",
    "prolog_engine = prolog.Prolog('./family.pl')\n",
    "prolog_engine.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prolog_engine.assert_facts(facts) # input the facts\n",
    "prolog_engine.query(\"abolish_all_tables.\") # reset the cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'X': 'mrs_bennet'}, {'X': 'charlotte'}]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prolog_engine.query('status(X,female),related(X,_,wife).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1302/1302 [06:54<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "dl_dataset = []\n",
    "for utterance in tqdm.tqdm(dataset):\n",
    "    parts = utterance['parts']\n",
    "    parts_count = len(parts)\n",
    "    \n",
    "    if \" and \" in utterance['target']:\n",
    "        print(utterance['target'], len(parts))\n",
    "    speaker = utterance['target']\n",
    "    discussion_index = utterance['discussion_index']\n",
    "    \n",
    "    utterance_text = re.sub('\\[X\\]', '', utterance['only_utterance_us'])\n",
    "    incises = [part for part in parts if not part['utterance']]\n",
    "    # for i in range(len(parts)):\n",
    "    #     if not parts[i]['utterance']:\n",
    "    #         continue\n",
    "    #     incises = (\n",
    "    #         [parts[i-1]] if i > 0 and not parts[i-1]['utterance'] else []\n",
    "    #         + [parts[i+1]] if i<parts_count-1 and not parts[i+1]['utterance'] else [])\n",
    "\n",
    "    concat_incise = \"\".join(part[\"text\"] for part in incises)\n",
    "    role = next((true_roles[part[\"speaker_role\"]] for part in incises if part[\"speaker_role\"] in true_roles), None)\n",
    "    gender = next((part[\"speaker_gender\"] for part in incises), None)\n",
    "    name = next((part[\"speaker_name\"] for part in incises), None)\n",
    "\n",
    "    potential_targets = []\n",
    "    query = []\n",
    "    if name is not None:\n",
    "        potential_targets = [name]\n",
    "    else:\n",
    "        if gender is not None:\n",
    "            query.append(\"status(X,{})\".format(\"female\" if gender is \"F\" else \"male\"))\n",
    "        if role is not None:\n",
    "            query.append(\"related(X,_,{})\".format(role))\n",
    "        if len(query)>0:\n",
    "            query = \",\".join(query)+\".\"\n",
    "            res = prolog_engine.query(query)\n",
    "            if isinstance(res, list):\n",
    "                potential_targets = set([people_code_to_name[r['X']] for r in res])\n",
    "            else:\n",
    "                potential_targets = set()\n",
    "\n",
    "    dl_dataset.append((discussion_index, utterance_text, concat_incise, potential_targets, speaker, role, gender, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(('said', 'VBD'), 'nsubj', ('mother', 'NN')),\n",
       "  (('mother', 'NN'), 'nmod:poss', ('her', 'PRP$')),\n",
       "  (('mother', 'NN'), 'amod', ('nice', 'JJ')),\n",
       "  (('said', 'VBD'), 'nmod', ('him', 'PRP')),\n",
       "  (('him', 'PRP'), 'case', ('to', 'TO'))]]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(re.sub(\"[^_\\w ]+\", \"\", \"her nice mother said to him, \"))\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "sum([[list(parse.triples()) for parse in dep_graphs] for dep_graphs in dep_parser.tagged_parse_sents([tagged])],[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset in multiple discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_discussions = []\n",
    "current_discussion = []\n",
    "current_discussion_index = None\n",
    "for sample in dl_dataset:\n",
    "    if sample[0] != current_discussion_index and len(current_discussion) > 0:\n",
    "        dataset_discussions.append(current_discussion)\n",
    "        current_discussion = []\n",
    "    current_discussion_index = sample[0]\n",
    "    current_discussion.append(sample[1:])\n",
    "if len(current_discussion) > 0:\n",
    "    dataset_discussions.append(current_discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dataset_discussions, open(\"corpus/dataset-prolog.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction only based on parsing and ontology results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.22964669738863286\n"
     ]
    }
   ],
   "source": [
    "correct_answers = 0\n",
    "people_names = [p['main'] for p in people_list]\n",
    "for discussion in dataset_discussions:\n",
    "    for sample in discussion:\n",
    "        if len(sample[2]) > 0 and np.random.choice(list(sample[2]), 1) == sample[3]:\n",
    "            correct_answers += 1\n",
    "print(\"accuracy: {}\".format(correct_answers/len(dl_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction only based on parsing and ontology results and nearby speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.2780337941628264\n"
     ]
    }
   ],
   "source": [
    "correct_answers = 0\n",
    "people_names = [p['main'] for p in people_list]\n",
    "for discussion in dataset_discussions:\n",
    "    discussion_people = set()\n",
    "    previous_predictions = [] \n",
    "    for i, sample in enumerate(discussion):\n",
    "        current_predictions = set()\n",
    "        if len(sample[2]) == 1:\n",
    "            current_predictions = {next(iter(sample[2]))}\n",
    "            discussion_people |= current_predictions\n",
    "        elif len(sample[2]) > 1:\n",
    "            current_predictions = sample[2] & discussion_people\n",
    "            around_predictions = set()\n",
    "            if i >= 2:\n",
    "                 around_predictions |= set(discussion[i-2][2])\n",
    "            if i < len(discussion)-2:\n",
    "                 around_predictions |= set(discussion[i+2][2])\n",
    "            # if i >= 4:\n",
    "            #      around_predictions |= set(discussion[i-4][2])\n",
    "            # if i < len(discussion)-4:\n",
    "            #      around_predictions |= set(discussion[i+4][2])\n",
    "            \n",
    "            if len(current_predictions) > 1:\n",
    "                if len(current_predictions & around_predictions) >= 1:\n",
    "                    current_predictions = current_predictions & around_predictions\n",
    "            elif len(current_predictions) == 0:\n",
    "                current_predictions = around_predictions\n",
    "        if len(current_predictions) == 1:\n",
    "            previous_predictions.append(next(iter(current_predictions)))\n",
    "        else:\n",
    "            previous_predictions.append(None)\n",
    "            \n",
    "        if len(current_predictions) > 0 and np.random.choice(list(current_predictions), 1) == sample[3]:\n",
    "            correct_answers += 1\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "print(\"accuracy: {}\".format(correct_answers/len(dl_dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
