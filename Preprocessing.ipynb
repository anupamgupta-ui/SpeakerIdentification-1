{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing\n",
    "Process the text to extract utterances and non-utterances and match the samples with the labelled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book utterances and non-utterances extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.character import characters\n",
    "from src.curation import curation\n",
    "\n",
    "curation(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Mrs_Annesley\n",
      "gender: F\n",
      "aliases: ['Mrs. Annesley', 'Annesley']\n",
      "name: Elizabeth_Bennet\n",
      "gender: F\n",
      "aliases: ['Elizabeth Bennet', 'Miss Elizabeth Bennet', 'Miss Elizabeth', 'Miss Lizzy', 'Miss Bennet', 'Miss Eliza', 'Eliza Bennet', 'Elizabeth', 'Lizzy', 'Liz', 'Eliza']\n",
      "name: Jane_Bennet\n",
      "gender: F\n",
      "aliases: ['Jane Bennet', 'Jane']\n",
      "name: Lydia_Bennet\n",
      "gender: F\n",
      "aliases: ['Lydia Bennet', 'Miss Lydia Bennet', 'Miss Lydia', 'Lydia']\n",
      "name: Kitty_Bennet\n",
      "gender: F\n",
      "aliases: ['Kitty Bennet', 'Catherine Bennet', 'Kitty']\n",
      "name: Mary_Bennet\n",
      "gender: F\n",
      "aliases: ['Mary Bennet', 'Mary']\n",
      "name: Mrs_Bennet\n",
      "gender: F\n",
      "aliases: ['Mrs. Bennet']\n",
      "name: Caroline_Bingley\n",
      "gender: F\n",
      "aliases: ['Caroline Bingley', 'Caroline', 'Miss Bingley']\n",
      "name: Charlotte\n",
      "gender: F\n",
      "aliases: ['Charlotte', 'Charlotte Lucas', 'Mrs. Collins', 'Miss Lucas']\n",
      "name: Lady_Catherine\n",
      "gender: F\n",
      "aliases: ['Lady Catherine', 'Catherine']\n",
      "name: Mr_Denny\n",
      "gender: F\n",
      "aliases: ['Mr. Denny']\n",
      "name: Lady_Anne_Darcy\n",
      "gender: F\n",
      "aliases: ['Lady Anne Darcy', 'Lady Anne', 'Anne']\n",
      "name: Georgiana_Darcy\n",
      "gender: F\n",
      "aliases: ['Georgiana Darcy', 'Georgiana', 'Miss Darcy']\n",
      "name: Miss_Grantley\n",
      "gender: F\n",
      "aliases: ['Miss Grantley']\n",
      "name: Mrs_Gardiner\n",
      "gender: F\n",
      "aliases: ['Mrs. Gardiner']\n",
      "name: Mrs_Hill\n",
      "gender: F\n",
      "aliases: ['Mrs. Hill']\n",
      "name: Mrs_Jenkinson\n",
      "gender: F\n",
      "aliases: ['Mrs. Jenkinson']\n",
      "name: Miss_Mary_King\n",
      "gender: F\n",
      "aliases: ['Miss Mary King', 'Mary King']\n",
      "name: Mrs_Long\n",
      "gender: F\n",
      "aliases: ['Mrs. Long']\n",
      "name: Lady_Lucas\n",
      "gender: F\n",
      "aliases: ['Lady Lucas']\n",
      "name: Maria_Lucas\n",
      "gender: F\n",
      "aliases: ['Maria Lucas', 'Miss Lucas', 'Maria']\n",
      "name: Louisa_Hurst\n",
      "gender: F\n",
      "aliases: ['Louisa Hurst', 'Louisa', 'Mrs. Hurst']\n",
      "name: Lady_Metcalfe\n",
      "gender: F\n",
      "aliases: ['Lady Metcalfe']\n",
      "name: Mrs_Nicholls\n",
      "gender: F\n",
      "aliases: ['Mrs. Nicholls', 'Nicholls']\n",
      "name: Miss_Pope\n",
      "gender: F\n",
      "aliases: ['Miss Pope']\n",
      "name: Mrs_Reynolds\n",
      "gender: F\n",
      "aliases: ['Mrs. Reynolds']\n",
      "name: Miss_Watson\n",
      "gender: F\n",
      "aliases: ['Miss Watson']\n",
      "name: Anne_de_Bourgh\n",
      "gender: F\n",
      "aliases: ['Anne de Bourgh', 'Miss de Bourgh', 'Bourgh']\n",
      "name: Mrs_Philips\n",
      "gender: F\n",
      "aliases: ['Mrs. Philips']\n",
      "name: Mr_Bennet\n",
      "gender: M\n",
      "aliases: ['Mr. Bennet', 'Bennet']\n",
      "name: Mr_Bingley\n",
      "gender: M\n",
      "aliases: ['Mr. Bingley', 'Bingley']\n",
      "name: Captain_Carter\n",
      "gender: M\n",
      "aliases: ['Captain Carter']\n",
      "name: Mr_Collins\n",
      "gender: M\n",
      "aliases: ['Mr. Collins', 'William Collins']\n",
      "name: Mr_Chamberlayne\n",
      "gender: M\n",
      "aliases: ['Mr. Chamberlayne']\n",
      "name: Dawson\n",
      "gender: M\n",
      "aliases: ['Dawson']\n",
      "name: Mr_Darcy\n",
      "gender: M\n",
      "aliases: ['Mr. Darcy', 'Mr. Fitzwilliam Darcy', 'Fitzwilliam Darcy', 'Darcy']\n",
      "name: Old_Mr_Darcy\n",
      "gender: M\n",
      "aliases: ['Old Mr. Darcy']\n",
      "name: Colonel_Fitzwilliam\n",
      "gender: M\n",
      "aliases: ['Colonel Fitzwilliam', 'Colonel F.']\n",
      "name: Colonel_Forster\n",
      "gender: M\n",
      "aliases: ['Colonel Forster']\n",
      "name: Mr_Gardiner\n",
      "gender: M\n",
      "aliases: ['Mr. Gardiner', 'EDW. Gardiner', 'E. Gardiner']\n",
      "name: William_Goulding\n",
      "gender: M\n",
      "aliases: ['William Goulding']\n",
      "name: Haggerston\n",
      "gender: M\n",
      "aliases: ['Haggerston']\n",
      "name: Mr_Jones\n",
      "gender: M\n",
      "aliases: ['Mr. Jones']\n",
      "name: Mr_Hurst\n",
      "gender: M\n",
      "aliases: ['Mr. Hurst']\n",
      "name: Mr_Morris\n",
      "gender: M\n",
      "aliases: ['Mr. Morris']\n",
      "name: Mr_Philips\n",
      "gender: M\n",
      "aliases: ['Mr. Philips', 'Philips']\n",
      "name: Mr_Pratt\n",
      "gender: M\n",
      "aliases: ['Mr. Pratt', 'Pratt']\n",
      "name: Mr_Robinson\n",
      "gender: M\n",
      "aliases: ['Mr. Robinson']\n",
      "name: Mr_Stone\n",
      "gender: M\n",
      "aliases: ['Mr. Stone']\n",
      "name: Old_Mr_Wickham\n",
      "gender: M\n",
      "aliases: ['Old Mr. Wickham']\n",
      "name: Sir_William\n",
      "gender: M\n",
      "aliases: ['Sir William', 'Sir William Lucas']\n",
      "name: Mr_Wickham\n",
      "gender: M\n",
      "aliases: ['Mr. Wickham', 'George Wickham', 'George', 'Wickham']\n"
     ]
    }
   ],
   "source": [
    "for character in characters:\n",
    "    print(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('corpus/curated_text.txt', 'r+') as raw_text_file:\n",
    "    # go through all lines in the book\n",
    "    text = raw_text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "annotations = []\n",
    "is_utterance = False\n",
    "processed = \"\"\n",
    "source = \"\"\n",
    "sample_parts = []\n",
    "text = re.sub(' +', ' ', \" \"+text) \n",
    "parts = list(p for p in re.split(\"(``)|('')\", text) if p is not None)\n",
    "i = 0\n",
    "next_quote_doesnt_count = False\n",
    "while i < len(parts):\n",
    "    part = parts[i]\n",
    "    if part == '``' or part == \"''\":\n",
    "        is_utterance = part == '``'\n",
    "        source += part\n",
    "        i += 1\n",
    "        continue\n",
    "    if not is_utterance:\n",
    "        if \"\\n\\n\" in part: # before or after an utterance\n",
    "            lines = part.split(\"\\n\\n\")\n",
    "            if processed != \"\":\n",
    "                if lines[0] != \"\":\n",
    "                    sample_parts.append({\"text\": lines[0], \"utterance\": False})\n",
    "                source += lines[0]\n",
    "                if processed[-5:] == \" [X] \":\n",
    "                    processed = processed[:-5]\n",
    "                if processed != \"\":\n",
    "                    annotations.append({\n",
    "                        \"only_utterance_us\": processed,\n",
    "                        \"source\": source,\n",
    "                        \"parts\": sample_parts\n",
    "                    })\n",
    "            processed = \"\"\n",
    "            if lines[-1] != \"\":\n",
    "                sample_parts = [({\"text\": lines[-1], \"utterance\": False})]\n",
    "            else:\n",
    "                sample_parts = []\n",
    "            source = lines[-1]\n",
    "        else: # in the middle of an utterance\n",
    "            sample_parts.append({\"text\": part, \"utterance\": False})\n",
    "            source += part\n",
    "            if part != \" -- \":\n",
    "                if processed[-5:] != \" [X] \":\n",
    "                    processed += \" [X] \"\n",
    "            else:\n",
    "                processed += \" \"\n",
    "    else:\n",
    "        sample_parts.append({\"text\": part, \"utterance\": True})\n",
    "        monoline = \" \".join(part.split(\"\\n\\n\"))\n",
    "        processed += monoline\n",
    "        source += monoline\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match the annotated dataset with the re-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_to_index = {annotation[\"only_utterance_us\"]: i for i, annotation in reversed(list(enumerate(annotations)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_equal(a, b, l):\n",
    "    return re.sub(r'(\\[X\\])|\\s', '', a)[:l] == re.sub(r'(\\[X\\])|\\s', '', b)[:l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My dear Elizabeth_Bennet, I have the highest opinion in the world of your excellent judgment in all matters within the scope of your understanding, but permit me to say that there must be a wide difference between the established forms of ceremony amongst the laity, and those which regulate the clergy; for give me leave to observe that I consider the clerical office as equal in point of dignity with the highest rank in the kingdom -- provided that a proper humility of behaviour is at the same time maintained. You must therefore allow me to follow the dictates of my conscience on this occasion, which leads me to perform what I look on as a point of duty. Pardon me for neglecting to profit by your advice, which on every other subject shall be my constant guide, though in the case before us I consider myself more fitted by education and habitual study to decide on what is right than a young lady like yourself. [X] apology, [X] Hunsford, [X] Lady_Catherine de Anne_de_Bourgh.\n",
      "--\n",
      "delightful, [X] charming,\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "with open('corpus/curated_dialogs.txt') as annoted_text_file:\n",
    "    annotated_text_lines = annoted_text_file.readlines()\n",
    "    for annoted_line in annotated_text_lines:\n",
    "        annotation_i, label, utterance = annoted_line.split('\\t')\n",
    "        utterance = re.sub('\\s+', ' ', utterance.strip())\n",
    "        if utterance in processed_to_index and \"target\" not in annotations[processed_to_index[utterance]]:\n",
    "            annotation = annotations[processed_to_index[utterance]]\n",
    "        else:\n",
    "            annotation = next((a for a in annotations if strip_equal(a['only_utterance_us'], utterance, 100) and \"target\" not in a), None)\n",
    "            if annotation['only_utterance_us'] != utterance:\n",
    "                print(annotation['only_utterance_us'])\n",
    "                print(\"--\")\n",
    "        assert \"target\" not in annotation\n",
    "        annotation[\"only_utterance_article\"] = utterance\n",
    "        annotation[\"target\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a in annotations:\n",
    "    if \"target\" not in a:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stanford parser annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the stanford parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.parse import stanford\n",
    "\n",
    "jar = 'stanford-parser-full-2017-06-09/stanford-parser.jar'\n",
    "model = 'stanford-parser-full-2017-06-09/stanford-parser-3.8.0-models.jar'\n",
    "\n",
    "dep_parser = stanford.StanfordDependencyParser(model, jar, model_path='edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz', encoding='utf8')\n",
    "\n",
    "#Add standford parser annotations like name or gender\n",
    "\n",
    "#######################################################\n",
    "# Stanford parser rules: triples -> name, gender, etc #\n",
    "#######################################################\n",
    "def extract_features(speaker_name, speaker_role, speaker_gender, triple):\n",
    "    (word1, tag1), dep, (word2, tag2) = triple\n",
    "    if (tag1.startswith('VBD') or word1 in ['said', 'added', 'cried', 'asked', 'replied', 'returned', 'continued', 'observed']) and (tag2.startswith('NN') or tag2.startswith('PRP')) and not dep.startswith('nmod'):\n",
    "        if tag2.startswith('NN'):\n",
    "            if tag2.startswith('NNP'):\n",
    "                speaker_name = word2\n",
    "            else:\n",
    "                speaker_role = word2\n",
    "        if word2 in ['he', 'man', 'boy', 'lad']:\n",
    "            speaker_gender = 'M'\n",
    "        if word2 in ['she', 'lady', 'girl']:\n",
    "            speaker_gender = 'F'\n",
    "    return (speaker_name, speaker_role, speaker_gender)\n",
    "\n",
    "\n",
    "for sample in annotations:\n",
    "    for part in sample[\"parts\"]:\n",
    "        if not part[\"utterance\"]:\n",
    "            speaker_name = None\n",
    "            speaker_role = None\n",
    "            speaker_gender = None\n",
    "            tokens = nltk.word_tokenize(part[\"text\"][:200])\n",
    "            tagged = nltk.pos_tag(tokens)\n",
    "            try:\n",
    "                dependencies = sum([[list(parse.triples()) for parse in dep_graphs] for dep_graphs in dep_parser.tagged_parse_sents([tagged])],[])\n",
    "                for (term1,dep,term2) in dependencies[0]:\n",
    "                    #print(term1, dep, term2)\n",
    "                    speaker_name, speaker_role, speaker_gender = extract_features(speaker_name, speaker_role, speaker_gender, (term1,dep,term2) )\n",
    "                    # try reverse order\n",
    "                    speaker_name, speaker_role, speaker_gender =  extract_features(speaker_name, speaker_role, speaker_gender, (term2,dep,term1) )\n",
    "            except Exception as e:\n",
    "                    print(e)\n",
    "                    print(part)\n",
    "            part[\"speaker_name\"] = speaker_name\n",
    "            part[\"speaker_role\"] = speaker_role\n",
    "            part[\"speaker_gender\"] = speaker_gender\n",
    "            #print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1294\n"
     ]
    }
   ],
   "source": [
    "print(len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'only_utterance_article': 'My dear Mr_Bennet, [X] have you heard that Netherfield Park is let at last?',\n",
       "  'only_utterance_us': 'My dear Mr_Bennet, [X] have you heard that Netherfield Park is let at last?',\n",
       "  'parts': [{'text': 'My dear Mr_Bennet,', 'utterance': True},\n",
       "   {'speaker_function': 'lady',\n",
       "    'speaker_gender': 'F',\n",
       "    'speaker_name': None,\n",
       "    'text': ' said his lady to him one day, ',\n",
       "    'utterance': False},\n",
       "   {'text': 'have you heard that Netherfield Park is let at last?',\n",
       "    'utterance': True}],\n",
       "  'source': \"``My dear Mr_Bennet,'' said his lady to him one day, ``have you heard that Netherfield Park is let at last?''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'But it is, [X] for Mrs_Long has just been here, and she told me all about it.',\n",
       "  'only_utterance_us': 'But it is, [X] for Mrs_Long has just been here, and she told me all about it.',\n",
       "  'parts': [{'text': 'But it is,', 'utterance': True},\n",
       "   {'speaker_function': None,\n",
       "    'speaker_gender': 'F',\n",
       "    'speaker_name': None,\n",
       "    'text': ' returned she; ',\n",
       "    'utterance': False},\n",
       "   {'text': 'for Mrs_Long has just been here, and she told me all about it.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``But it is,'' returned she; ``for Mrs_Long has just been here, and she told me all about it.''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'Do not you want to know who has taken it?',\n",
       "  'only_utterance_us': 'Do not you want to know who has taken it?',\n",
       "  'parts': [{'text': 'Do not you want to know who has taken it?',\n",
       "    'utterance': True},\n",
       "   {'speaker_function': 'wife',\n",
       "    'speaker_gender': None,\n",
       "    'speaker_name': None,\n",
       "    'text': ' cried his wife impatiently.',\n",
       "    'utterance': False}],\n",
       "  'source': \"``Do not you want to know who has taken it?'' cried his wife impatiently.\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': '_You_ want to tell me, and I have no objection to hearing it.',\n",
       "  'only_utterance_us': '_You_ want to tell me, and I have no objection to hearing it.',\n",
       "  'parts': [{'text': '_You_ want to tell me, and I have no objection to hearing it.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``_You_ want to tell me, and I have no objection to hearing it.''\",\n",
       "  'target': 'Mr_Bennet'},\n",
       " {'only_utterance_article': 'Why, my dear, you must know, Mrs_Long says that Netherfield is taken by a young man of large fortune from the north of England; that he came down on Monday in a chaise and four to see the place, and was so much delighted with it that he agreed with Mr_Morris immediately; that he is to take possession before Michaelmas, and some of his servants are to be in the house by the end of next week.',\n",
       "  'only_utterance_us': 'Why, my dear, you must know, Mrs_Long says that Netherfield is taken by a young man of large fortune from the north of England; that he came down on Monday in a chaise and four to see the place, and was so much delighted with it that he agreed with Mr_Morris immediately; that he is to take possession before Michaelmas, and some of his servants are to be in the house by the end of next week.',\n",
       "  'parts': [{'text': 'Why, my dear, you must know, Mrs_Long says that Netherfield is taken by a young man of large fortune from the north of England; that he came down on Monday in a chaise and four to see the place, and was so much delighted with it that he agreed with Mr_Morris immediately; that he is to take possession before Michaelmas, and some of his servants are to be in the house by the end of next week.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``Why, my dear, you must know, Mrs_Long says that Netherfield is taken by a young man of large fortune from the north of England; that he came down on Monday in a chaise and four to see the place, and was so much delighted with it that he agreed with Mr_Morris immediately; that he is to take possession before Michaelmas, and some of his servants are to be in the house by the end of next week.''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'What is his name?',\n",
       "  'only_utterance_us': 'What is his name?',\n",
       "  'parts': [{'text': 'What is his name?', 'utterance': True}],\n",
       "  'source': \"``What is his name?''\",\n",
       "  'target': 'Mr_Bennet'},\n",
       " {'only_utterance_article': 'Mr_Bingley.',\n",
       "  'only_utterance_us': 'Mr_Bingley.',\n",
       "  'parts': [{'text': 'Mr_Bingley.', 'utterance': True}],\n",
       "  'source': \"``Mr_Bingley.''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'Is he married or single?',\n",
       "  'only_utterance_us': 'Is he married or single?',\n",
       "  'parts': [{'text': 'Is he married or single?', 'utterance': True}],\n",
       "  'source': \"``Is he married or single?''\",\n",
       "  'target': 'Mr_Bennet'},\n",
       " {'only_utterance_article': 'Oh! single, my dear, to be sure! A single man of large fortune; four or five thousand a year. What a fine thing for our girls!',\n",
       "  'only_utterance_us': 'Oh! single, my dear, to be sure! A single man of large fortune; four or five thousand a year. What a fine thing for our girls!',\n",
       "  'parts': [{'text': 'Oh! single, my dear, to be sure! A single man of large fortune; four or five thousand a year. What a fine thing for our girls!',\n",
       "    'utterance': True}],\n",
       "  'source': \"``Oh! single, my dear, to be sure! A single man of large fortune; four or five thousand a year. What a fine thing for our girls!''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'How so? how can it affect them?',\n",
       "  'only_utterance_us': 'How so? how can it affect them?',\n",
       "  'parts': [{'text': 'How so? how can it affect them?', 'utterance': True}],\n",
       "  'source': \"``How so? how can it affect them?''\",\n",
       "  'target': 'Mr_Bennet'},\n",
       " {'only_utterance_article': 'My dear Mr_Bennet, [X] how can you be so tiresome! You must know that I am thinking of his marrying one of them.',\n",
       "  'only_utterance_us': 'My dear Mr_Bennet, [X] how can you be so tiresome! You must know that I am thinking of his marrying one of them.',\n",
       "  'parts': [{'text': 'My dear Mr_Bennet,', 'utterance': True},\n",
       "   {'speaker_function': None,\n",
       "    'speaker_gender': None,\n",
       "    'speaker_name': None,\n",
       "    'text': ' replied his wife, ',\n",
       "    'utterance': False},\n",
       "   {'text': 'how can you be so tiresome! You must know that I am thinking of his marrying one of them.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``My dear Mr_Bennet,'' replied his wife, ``how can you be so tiresome! You must know that I am thinking of his marrying one of them.''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'Is that his design in settling here?',\n",
       "  'only_utterance_us': 'Is that his design in settling here?',\n",
       "  'parts': [{'text': 'Is that his design in settling here?',\n",
       "    'utterance': True}],\n",
       "  'source': \"``Is that his design in settling here?''\",\n",
       "  'target': 'Mr_Bennet'},\n",
       " {'only_utterance_article': 'Design! nonsense, how can you talk so! But it is very likely that he _may_ fall in love with one of them, and therefore you must visit him as soon as he comes.',\n",
       "  'only_utterance_us': 'Design! nonsense, how can you talk so! But it is very likely that he _may_ fall in love with one of them, and therefore you must visit him as soon as he comes.',\n",
       "  'parts': [{'text': 'Design! nonsense, how can you talk so! But it is very likely that he _may_ fall in love with one of them, and therefore you must visit him as soon as he comes.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``Design! nonsense, how can you talk so! But it is very likely that he _may_ fall in love with one of them, and therefore you must visit him as soon as he comes.''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'I see no occasion for that. You and the girls may go, or you may send them by themselves, which perhaps will be still better; for, as you are as handsome as any of them, Mr_Bingley might like you the best of the party.',\n",
       "  'only_utterance_us': 'I see no occasion for that. You and the girls may go, or you may send them by themselves, which perhaps will be still better; for, as you are as handsome as any of them, Mr_Bingley might like you the best of the party.',\n",
       "  'parts': [{'text': 'I see no occasion for that. You and the girls may go, or you may send them by themselves, which perhaps will be still better; for, as you are as handsome as any of them, Mr_Bingley might like you the best of the party.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``I see no occasion for that. You and the girls may go, or you may send them by themselves, which perhaps will be still better; for, as you are as handsome as any of them, Mr_Bingley might like you the best of the party.''\",\n",
       "  'target': 'Mr_Bennet'},\n",
       " {'only_utterance_article': 'My dear, you flatter me. I certainly _have_ had my share of beauty, but I do not pretend to be any thing extraordinary now. When a woman has five grown up daughters, she ought to give over thinking of her own beauty.',\n",
       "  'only_utterance_us': 'My dear, you flatter me. I certainly _have_ had my share of beauty, but I do not pretend to be any thing extraordinary now. When a woman has five grown up daughters, she ought to give over thinking of her own beauty.',\n",
       "  'parts': [{'text': 'My dear, you flatter me. I certainly _have_ had my share of beauty, but I do not pretend to be any thing extraordinary now. When a woman has five grown up daughters, she ought to give over thinking of her own beauty.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``My dear, you flatter me. I certainly _have_ had my share of beauty, but I do not pretend to be any thing extraordinary now. When a woman has five grown up daughters, she ought to give over thinking of her own beauty.''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'In such cases, a woman has not often much beauty to think of.',\n",
       "  'only_utterance_us': 'In such cases, a woman has not often much beauty to think of.',\n",
       "  'parts': [{'text': 'In such cases, a woman has not often much beauty to think of.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``In such cases, a woman has not often much beauty to think of.''\",\n",
       "  'target': 'Mr_Bennet'},\n",
       " {'only_utterance_article': 'But, my dear, you must indeed go and see Mr_Bingley when he comes into the neighbourhood.',\n",
       "  'only_utterance_us': 'But, my dear, you must indeed go and see Mr_Bingley when he comes into the neighbourhood.',\n",
       "  'parts': [{'text': 'But, my dear, you must indeed go and see Mr_Bingley when he comes into the neighbourhood.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``But, my dear, you must indeed go and see Mr_Bingley when he comes into the neighbourhood.''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'It is more than I engage for, I assure you.',\n",
       "  'only_utterance_us': 'It is more than I engage for, I assure you.',\n",
       "  'parts': [{'text': 'It is more than I engage for, I assure you.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``It is more than I engage for, I assure you.''\",\n",
       "  'target': 'Mr_Bennet'},\n",
       " {'only_utterance_article': 'But consider your daughters. Only think what an establishment it would be for one of them. Sir_William and Lady_Lucas are determined to go, merely on that account, for in general, you know they visit no new comers. Indeed you must go, for it will be impossible for us to visit him, if you do not.',\n",
       "  'only_utterance_us': 'But consider your daughters. Only think what an establishment it would be for one of them. Sir_William and Lady_Lucas are determined to go, merely on that account, for in general, you know they visit no new comers. Indeed you must go, for it will be impossible for us to visit him, if you do not.',\n",
       "  'parts': [{'text': 'But consider your daughters. Only think what an establishment it would be for one of them. Sir_William and Lady_Lucas are determined to go, merely on that account, for in general, you know they visit no new comers. Indeed you must go, for it will be impossible for us to visit him, if you do not.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``But consider your daughters. Only think what an establishment it would be for one of them. Sir_William and Lady_Lucas are determined to go, merely on that account, for in general, you know they visit no new comers. Indeed you must go, for it will be impossible for us to visit him, if you do not.''\",\n",
       "  'target': 'Mrs_Bennet'},\n",
       " {'only_utterance_article': 'You are over-scrupulous, surely. I dare say Mr_Bingley will be very glad to see you; and I will send a few lines by you to assure him of my hearty consent to his marrying which ever he chuses of the girls; though I must throw in a good word for my little Elizabeth_Bennet.',\n",
       "  'only_utterance_us': 'You are over-scrupulous, surely. I dare say Mr_Bingley will be very glad to see you; and I will send a few lines by you to assure him of my hearty consent to his marrying which ever he chuses of the girls; though I must throw in a good word for my little Elizabeth_Bennet.',\n",
       "  'parts': [{'text': 'You are over-scrupulous, surely. I dare say Mr_Bingley will be very glad to see you; and I will send a few lines by you to assure him of my hearty consent to his marrying which ever he chuses of the girls; though I must throw in a good word for my little Elizabeth_Bennet.',\n",
       "    'utterance': True}],\n",
       "  'source': \"``You are over-scrupulous, surely. I dare say Mr_Bingley will be very glad to see you; and I will send a few lines by you to assure him of my hearty consent to his marrying which ever he chuses of the girls; though I must throw in a good word for my little Elizabeth_Bennet.''\",\n",
       "  'target': 'Mr_Bennet'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the annotated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(annotations, open(\"corpus/dataset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To facilitate comparison with curated_dialogs.txt\n",
    "with open('corpus/dataset.pkl', 'rb') as pick:\n",
    "    with open('corpus/dataset.txt', 'w+') as text:\n",
    "        annotations = pickle.load(pick)\n",
    "        for a in annotations:\n",
    "            parts = \" \".join(re.sub(r'\\n', ' ', part[\"text\"]) for part in a[\"parts\"])\n",
    "            text.write(parts[:200] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'only_utterance_us': 'for your housekeeper, [X] informed us that you would certainly not be here till to-morrow; and indeed, before we left Bakewell we understood that you were not immediately expected in the country. [X] They will join me early tomorrow, [X] and among them are some who will claim an acquaintance with you, -- Mr_Bingley and his sisters.', 'source': \"After walking some time in this way, the two ladies in front, the two gentlemen behind, on resuming their places after descending to the brink of the river for the better inspection of some curious water-plant, there chanced to be a little alteration. It originated in Mrs_Gardiner, who, fatigued by the exercise of the morning, found Elizabeth_Bennet's arm inadequate to her support, and consequently preferred her husband's. Mr_Darcy took her place by her niece, and they walked on together. After a short silence, the lady first spoke. She wished him to know that she had been assured of his absence before she came to the place, and accordingly began by observing that his arrival had been very unexpected -- ``for your housekeeper,'' she added, ``informed us that you would certainly not be here till to-morrow; and indeed, before we left Bakewell we understood that you were not immediately expected in the country.'' He acknowledged the truth of it all; and said that business with his steward had occasioned his coming forward a few hours before the rest of the party with whom he had been travelling. ``They will join me early tomorrow,'' he continued, ``and among them are some who will claim an acquaintance with you, -- Mr_Bingley and his sisters.''\", 'parts': [{'text': \"After walking some time in this way, the two ladies in front, the two gentlemen behind, on resuming their places after descending to the brink of the river for the better inspection of some curious water-plant, there chanced to be a little alteration. It originated in Mrs_Gardiner, who, fatigued by the exercise of the morning, found Elizabeth_Bennet's arm inadequate to her support, and consequently preferred her husband's. Mr_Darcy took her place by her niece, and they walked on together. After a short silence, the lady first spoke. She wished him to know that she had been assured of his absence before she came to the place, and accordingly began by observing that his arrival had been very unexpected -- \", 'utterance': False, 'speaker_name': None, 'speaker_function': None, 'speaker_gender': None}, {'text': 'for your housekeeper,', 'utterance': True}, {'text': ' she added, ', 'utterance': False, 'speaker_name': None, 'speaker_function': None, 'speaker_gender': 'F'}, {'text': 'informed us that you would certainly not be here till to-morrow; and indeed, before we left Bakewell we understood that you were not immediately expected in the country.', 'utterance': True}, {'text': ' He acknowledged the truth of it all; and said that business with his steward had occasioned his coming forward a few hours before the rest of the party with whom he had been travelling. ', 'utterance': False, 'speaker_name': None, 'speaker_function': 'truth', 'speaker_gender': None}, {'text': 'They will join me early tomorrow,', 'utterance': True}, {'text': ' he continued, ', 'utterance': False, 'speaker_name': None, 'speaker_function': None, 'speaker_gender': 'M'}, {'text': 'and among them are some who will claim an acquaintance with you, -- Mr_Bingley and his sisters.', 'utterance': True}], 'only_utterance_article': 'for your housekeeper, [X] informed us that you would certainly not be here till to-morrow; and indeed, before we left Bakewell we understood that you were not immediately expected in the country. [X] They will join me early tomorrow, [X] and among them are some who will claim an acquaintance with you, -- Mr_Bingley and his sisters.', 'target': 'Elizabeth_Bennet and Mr_Darcy'}\n"
     ]
    }
   ],
   "source": [
    "with open('corpus/dataset.pkl', 'rb') as pick:\n",
    "    annotations2 = pickle.load(pick)\n",
    "    print(annotations2[858])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.parse import stanford\n",
    "\n",
    "jar = '../stanford-parser-full-2017-06-09/stanford-parser.jar'\n",
    "model = '../stanford-parser-full-2017-06-09/stanford-parser-3.8.0-models.jar'\n",
    "\n",
    "dep_parser = stanford.StanfordDependencyParser(model, jar, model_path='edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_triple(triple, speaker_name, speaker_role, speaker_gender, tokens_position):\n",
    "    (word1, tag1), dep, (word2, tag2) = triple\n",
    "    if ((tag1.startswith('VBD') or word1 in ['said', 'added', 'cried', 'asked', 'replied', 'returned', 'continued', 'observed']) and \\\n",
    "        (tag2.startswith('NN') or tag2.startswith('PRP')) and \\\n",
    "         not dep.startswith('nmod')) \\\n",
    "        or (tag1.startswith('VBD') and dep == \"dobj\" and tokens_position[(word1, tag1)] == 0):\n",
    "        if tag2.startswith('NN'):\n",
    "            if tag2.startswith('NNP'):\n",
    "                speaker_name = word2\n",
    "                print(\"speaker_name = {}: {}\".format(speaker_name, str(triple)))\n",
    "            elif word2 in true_roles:\n",
    "                speaker_role = word2\n",
    "                print(\"speaker_role = {}: {}\".format(speaker_role, str(triple)))\n",
    "        if word2 in ['he', 'man', 'boy', 'lad']:\n",
    "            speaker_gender = 'M'\n",
    "            print(\"speaker_gender = {}: {}\".format(speaker_gender, str(triple)))\n",
    "        if word2 in ['she', 'lady', 'girl']:\n",
    "            speaker_gender = 'F'\n",
    "            print(\"speaker_gender = {}: {}\".format(speaker_gender, str(triple)))\n",
    "    return (speaker_name, speaker_role, speaker_gender)\n",
    "\n",
    "def extract_features_from_text(text):\n",
    "    tokens = nltk.word_tokenize(\n",
    "        text\n",
    "    )\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    tokens_position = {v: i for i, v in enumerate(tagged)}\n",
    "    speaker_name, speaker_role, speaker_gender = None, None, None\n",
    "    triples = sum([[list(parse.triples()) for parse in dep_graphs] for dep_graphs in dep_parser.tagged_parse_sents([tagged])],[])[0]\n",
    "    for triple in triples:\n",
    "        speaker_name, speaker_role, speaker_gender = extract_features_from_triple(triple, speaker_name, speaker_role, speaker_gender, tokens_position)\n",
    "    return (speaker_name, speaker_role, speaker_gender), triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, None, None),\n",
       " [(('sang', 'NN'), 'nmod:poss', ('My', 'PRP$')),\n",
       "  (('sang', 'NN'), 'compound', ('husband', 'NN')),\n",
       "  (('sang', 'NN'), 'nmod', ('me', 'PRP')),\n",
       "  (('me', 'PRP'), 'case', ('for', 'IN'))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features_from_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_prp = [\"i\", \"you\", \"he\", \"she\", \"we\", \"they\", \"somebody\", \"anybody\", \"noone\", \"anyone\", \"it\"]\n",
    "obj_prp = [\"me\", \"you\", \"him\", \"her\", \"us\", \"them\", \"somebody\", \"anybody\", \"noone\", \"anyone\", \"it\"]\n",
    "expression_verbs = [stemmer.stem(v) for v in ['said', 'added', 'cried', 'asked', 'replied', 'returned', 'continued', 'observed', 'call', 'read']]\n",
    "true_roles = {\n",
    "    \"husband\": \"husband\",\n",
    "    \"ladi\": \"wife\",\n",
    "    \"wife\": \"wife\",\n",
    "    \"aunt\": \"aunt\",\n",
    "    \"uncl\": \"uncle\",\n",
    "    \"father\": \"father\",\n",
    "    \"sister\": \"sister\",\n",
    "    \"mother\": \"mother\",\n",
    "    \"daughter\": \"daughter\",\n",
    "    \"son\": \"son\",\n",
    "    \"cousin\": \"cousin\",\n",
    "    \"fiance\": \"married\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fiance',\n",
       " 'son',\n",
       " 'ladi',\n",
       " 'aunt',\n",
       " 'husband',\n",
       " 'sister',\n",
       " 'father',\n",
       " 'wife',\n",
       " 'cousin',\n",
       " 'mother',\n",
       " 'daughter',\n",
       " 'uncl']"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stemmer.stem(r) for r in true_roles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(\n",
    "    \"repeated Caroline_Bingley to her sister.\"\n",
    ")\n",
    "tagged = [(str(i), t) for i, (s, t) in enumerate(nltk.pos_tag(tokens))]\n",
    "stemmed = [stemmer.stem(t) for t in tokens]\n",
    "triples = sum([[list(parse.triples()) for parse in dep_graphs] for dep_graphs in dep_parser.tagged_parse_sents([tagged])],[])[0]\n",
    "# detect the subj of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the subject\n",
    "def extract_subj_from_triples(triples, stemmed, return_ranks=False):\n",
    "    subj_ranks = [0] * len(stemmed)\n",
    "    for (p1, t1), dep, (p2, t2) in triples:\n",
    "        p1, p2 = int(p1), int(p2)\n",
    "        if t2.startswith(\"NN\"):\n",
    "            subj_ranks[p2] += 1\n",
    "        if t2.startswith(\"PRP\") and stemmed[p2] in subj_prp:\n",
    "            subj_ranks[p2] += 1\n",
    "        if dep == 'nsubj': # word is marked as subject\n",
    "            if p1 == 0:\n",
    "                subj_ranks[p2] += 1\n",
    "            else:\n",
    "                subj_ranks[p2] += 2\n",
    "        if t1.startswith(\"VB\"): # if it is a dependency toward a verb\n",
    "            subj_ranks[p2] += 1\n",
    "            if p1 == 0: # first verb after utterance\n",
    "                subj_ranks[p2] += 1\n",
    "                if dep.startswith(\"dobj\"):\n",
    "                    subj_ranks[p2] += 1\n",
    "        if stemmed[p1] in expression_verbs:\n",
    "            subj_ranks[p2] += 1\n",
    "    subj_score, subj = max(zip(subj_ranks, range(len(stemmed))))\n",
    "    if return_ranks:\n",
    "        return subj_score, subj, subj_ranks\n",
    "    return subj_score, subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "#Extract the destination charater\n",
    "def extract_dest_from_triples(triples, stemmed, return_ranks=False):\n",
    "    dest_ranks = [0] * len(stemmed)\n",
    "    for (p1, t1), dep, (p2, t2) in triples:\n",
    "        p1, p2 = int(p1), int(p2)\n",
    "        if t2.startswith(\"NN\"):\n",
    "            dest_ranks[p2] += 1\n",
    "        if t2.startswith(\"PRP\") and stemmed[p2] in obj_prp:\n",
    "            dest_ranks[p2] += 1\n",
    "        if t1.startswith(\"VB\"): # if it is a dependency toward a verb\n",
    "            dest_ranks[p2] += 1\n",
    "            if p1 == 0: # first verb after utterance\n",
    "                dest_ranks[p2] += 1\n",
    "        if dep.startswith(\"nmod\"):\n",
    "            dest_ranks[p2] += 1\n",
    "        if stemmed[p1] in expression_verbs:\n",
    "            dest_ranks[p2] += 1\n",
    "    dest_score, dest = max(zip(dest_ranks, range(len(stemmed))))\n",
    "    if return_ranks:\n",
    "        return dest_score, dest, dest_ranks\n",
    "    return dest_score, dest\n",
    "\n",
    "\n",
    "#Extract the relation\n",
    "def extract_relational_mod_from_triples(triples, stemmed, token_i, return_ranks=False):\n",
    "    nmod_ranks = [0] * len(stemmed)\n",
    "    for (p1, t1), dep, (p2, t2) in triples:\n",
    "        p1, p2 = int(p1), int(p2)\n",
    "        if p1 != token_i:\n",
    "            continue\n",
    "        if t2.startswith(\"NN\"):\n",
    "            nmod_ranks[p2] += 1\n",
    "        if t2.startswith(\"PRP\"):\n",
    "            nmod_ranks[p2] += 1\n",
    "        if dep.startswith(\"nmod\"):\n",
    "            nmod_ranks[p2] += 1\n",
    "        if stemmed[p1] in expression_verbs:\n",
    "            nmod_ranks[p2] += 1\n",
    "    nmod = max(range(len(nmod_ranks)), key=lambda x: nmod_ranks[x])\n",
    "    nmod_score, nmod = max(zip(nmod_ranks, range(len(stemmed))))\n",
    "    if return_ranks:\n",
    "        return nmod_score, nmod, nmod_ranks\n",
    "    return nmod_score, nmod\n",
    "\n",
    "def extract_features_from_token(token, *token_codes):\n",
    "    names, properties = set(), set()\n",
    "    return names, properties\n",
    "\n",
    "def get_tree_leaves(tree, root_i):\n",
    "    def _rec(i):\n",
    "        node = tree.get_by_address(i)\n",
    "        yield (node['address'] - 1)\n",
    "        for [v] in node['deps'].values():\n",
    "            yield from _rec(v)\n",
    "    \n",
    "    return sorted(list(_rec(root_i+1)))\n",
    "\n",
    "def switch_tokens_in_tree(token1_root, token2_root, tree, lists, remove1=False, remove2=False):\n",
    "    tokens1 = [t for t in get_tree_leaves(tree, token1_root)]\n",
    "    tokens2 = [t for t in get_tree_leaves(tree, token2_root)]\n",
    "    f1, f2 = tokens1[0], tokens2[0]\n",
    "    tokens1, tokens2 = sorted((tokens1, tokens2))\n",
    "    for l in lists:\n",
    "        newl = []\n",
    "        for i in range(len(l)):\n",
    "            if i == f1 and not remove2:\n",
    "                newl.extend([l[t] for t in tokens2])\n",
    "            if i == f2 and not remove1:\n",
    "                newl.extend([l[t] for t in tokens1])\n",
    "            if i not in tokens1 and i not in tokens2:\n",
    "                newl.append(l[i])\n",
    "        yield newl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_text(text, debug=False):\n",
    "    text = text if text.strip()[0] in string.ascii_uppercase else 'XXX ' + text\n",
    "    try:\n",
    "        tree = next(parser.raw_parse(text))\n",
    "    except Exception as e:\n",
    "        return (tuple([None]*4), tuple([None]*4))\n",
    "        \n",
    "    token_count = max(a for a in tree.nodes)\n",
    "    stemmed = ['']*token_count\n",
    "    tagged = [('', '') for i in range(token_count)]\n",
    "    for i, n in tree.nodes.items():\n",
    "        if i != 0:\n",
    "            stemmed[i-1] = stemmer.stem(n['word']) if n['word'][0] not in string.ascii_uppercase else n['word']\n",
    "            tagged[i-1] = (n['word'], n['ctag'])\n",
    "\n",
    "    triples = list(custom_triples(tree.root, tree))\n",
    "\n",
    "    if debug:\n",
    "        print(\"--- triples ---\")\n",
    "        display(triples)\n",
    "        print(\"--- stemmed ---\")\n",
    "        display(stemmed, token_count)\n",
    "\n",
    "    subj_score, subj, subj_ranks = extract_subj_from_triples(triples, stemmed, return_ranks=True)\n",
    "    if debug:\n",
    "        display(list(enumerate(zip(subj_ranks, stemmed))))\n",
    "\n",
    "    parser_nsubj_triples = [t for t in triples if t[1].startswith('nsubj')]\n",
    "\n",
    "    # If the fake subject was picked, then switch it with the dobj and remove it from the sentence\n",
    "    if stemmed[subj] == 'XXX':\n",
    "        parser_verb = next(t[0][0] for t in triples if t[2][0] == subj and t[1].startswith('nsubj'))\n",
    "        parser_dobj = next((t[2][0] for t in triples if t[0][0] == parser_verb and t[1].startswith('dobj')), None)\n",
    "\n",
    "        if parser_dobj is not None:\n",
    "            print(tagged)\n",
    "            tagged, stemmed = tuple(switch_tokens_in_tree(subj, parser_dobj, tree, (tagged, stemmed), remove1=True))\n",
    "            tree = next(dep_parser.tagged_parse(tagged))\n",
    "            triples = list(custom_triples(tree.root, tree))\n",
    "\n",
    "            subj_score, subj, subj_ranks = extract_subj_from_triples(triples, stemmed, return_ranks=True)\n",
    "            if debug:\n",
    "                print(\"re-parsing with\", stemmed)\n",
    "                print(\"--- triples ---\")\n",
    "                display(triples)\n",
    "                print(\"--- stemmed ---\")\n",
    "                display(stemmed, token_count)\n",
    "                display(list(enumerate(zip(subj_ranks, stemmed))))\n",
    "\n",
    "\n",
    "    dest_score, dest, dest_ranks = extract_dest_from_triples(triples, stemmed, return_ranks=True)\n",
    "    if debug:\n",
    "        display(list(enumerate(zip(dest_ranks, stemmed))))\n",
    "    if dest == subj or dest_score < 3 or abs(dest-subj) > 40:\n",
    "        dest = None\n",
    "\n",
    "    subj_names, subj_properties = set(), set()\n",
    "    dest_names, dest_properties = set(), set()\n",
    "\n",
    "    if subj is not None:\n",
    "        # + 1 because the 0 node is for the empty root only\n",
    "        for sub_subj in get_tree_leaves(tree, subj):\n",
    "            subj_token = stemmed[sub_subj]\n",
    "            if subj_token[0] in string.ascii_uppercase:\n",
    "                subj_names.add(subj_token)\n",
    "            if subj_token in ['he', 'man', 'boy', 'lad', 'him']:\n",
    "                subj_properties.add('status(X, male)')\n",
    "            elif subj_token in ['she', 'ladi', 'girl']:\n",
    "                subj_properties.add('status(X, female)')\n",
    "            if subj_token in true_roles:\n",
    "                subj_properties.add('related(X, Y, {})'.format(subj_token))\n",
    "\n",
    "            subj_nmod_score, subj_nmod = extract_relational_mod_from_triples(triples, stemmed, subj)\n",
    "            if subj_nmod_score >= 1:\n",
    "                subj_nmod_token = stemmed[subj_nmod]\n",
    "                if subj_nmod_token in ['his', 'he', 'him']:\n",
    "                    subj_properties.add('status(Y, male)')\n",
    "                elif subj_nmod_token in ['her', 'she']:\n",
    "                    subj_properties.add('status(Y, female)')\n",
    "\n",
    "\n",
    "    if dest is not None:\n",
    "        # + 1 because the 0 node is for the empty root only\n",
    "        for sub_dest in get_tree_leaves(tree, dest):\n",
    "            dest_token = stemmed[sub_dest]\n",
    "\n",
    "            if dest_token[0] in string.ascii_uppercase:\n",
    "                dest_names.add(dest_token)\n",
    "            if dest_token in ['he', 'man', 'boy', 'lad', 'him']:\n",
    "                dest_properties.add('status(U, male)')\n",
    "            elif dest_token in ['she', 'ladi', 'girl']:\n",
    "                dest_properties.add('status(U, female)')\n",
    "            if dest_token in true_roles:\n",
    "                dest_properties.add('related(U, V, {})'.format(dest_token))\n",
    "\n",
    "            dest_nmod_score, dest_nmod = extract_relational_mod_from_triples(triples, stemmed, dest)\n",
    "            if dest_nmod_score >= 1:\n",
    "                dest_nmod_token = stemmed[dest_nmod]\n",
    "                if dest_nmod_token in ['his', 'he', 'him']:\n",
    "                    dest_properties.add('status(V, male)')\n",
    "                elif dest_nmod_token in ['her', 'she']:\n",
    "                    dest_properties.add('status(V, female)')\n",
    "                \n",
    "    return (subj_names, subj_properties), (dest_names, dest_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pickle.load(open(\"corpus/people.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test ok '"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('([A-Z][a-z])*s+([^\\w])', r'\\1\\2', \"Tests ok \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_utterance(text, people, debug=False):\n",
    "    people_to_code = {p['main'].strip('s'): p['code'] for p in people}\n",
    "    text = re.sub('([A-Z][a-z])*s+([^\\w])', r'\\1\\2', text)\n",
    "            \n",
    "    try:\n",
    "        tree = next(parser.raw_parse(text))\n",
    "    except Exception as e:\n",
    "        return (tuple([None]*4), tuple([None]*4))\n",
    "        \n",
    "    token_count = max(a for a in tree.nodes)\n",
    "    stemmed = ['']*token_count\n",
    "    tagged = [('', '') for i in range(token_count)]\n",
    "    for i, n in tree.nodes.items():\n",
    "        if i != 0:\n",
    "            stemmed[i-1] = stemmer.stem(n['word']) if n['word'] not in people_to_code else n['word']\n",
    "            tagged[i-1] = (n['word'], n['ctag'])\n",
    "\n",
    "    triples = list(custom_triples(tree.root, tree))\n",
    "\n",
    "    if debug:\n",
    "        print(\"--- triples ---\")\n",
    "        display(sorted(triples, key=lambda x: (x[0][0], x[2][0])))\n",
    "        print(\"--- stemmed ---\")\n",
    "        display(list(enumerate(stemmed)), token_count)\n",
    "\n",
    "    subj_names, subj_properties = set(), set()\n",
    "    dest_names, dest_properties = set(), set()\n",
    "\n",
    "        # + 1 because the 0 node is for the empty root only\n",
    "    for_subj = True\n",
    "    non_anaphore = set()\n",
    "    for i, triple in enumerate(triples):\n",
    "        if triple[1] == 'nsubj' and triple[0][1].startswith('VB'):\n",
    "            non_anaphore.add(triple[2][0])\n",
    "        if triple[1] == 'nmod:poss':\n",
    "            if stemmed[triple[2][0]] == 'my':\n",
    "                for_subj = True\n",
    "            elif stemmed[triple[2][0]] == 'your':\n",
    "                for_subj = False\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            poss = triple[0][0]\n",
    "            print(people_to_code)\n",
    "            for sub in get_tree_leaves(tree, poss):\n",
    "                token = stemmed[sub]\n",
    "                print(token)\n",
    "                if token in true_roles:\n",
    "                    if for_subj:\n",
    "                        subj_properties.add('related(Y{}, X, {})'.format(i, true_roles[token]))\n",
    "                    else:\n",
    "                        dest_properties.add('related(V{}, U, {})'.format(i, true_roles[token]))\n",
    "                elif token in people_to_code:\n",
    "                    if for_subj:\n",
    "                        subj_properties.add('Y{}={}'.format(i, people_to_code[token]))\n",
    "                    else:\n",
    "                        dest_properties.add('V{}={}'.format(i, people_to_code[token]))\n",
    "    other_mentions = [i for i, t in enumerate(stemmed) if t in ('you', 'your', 'dear')]\n",
    "    people_names = [t for i, t in enumerate(stemmed)\n",
    "                    if t in people_to_code and\n",
    "                       i not in non_anaphore and\n",
    "                       len([j for j in other_mentions if abs(i-j)<5]) > 0]\n",
    "    \n",
    "    if len(people_names) > 0:\n",
    "        dest_names.add(people_names[0])\n",
    "                    \n",
    "                \n",
    "    return (subj_names, subj_properties), (dest_names, dest_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- triples ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((3, 'VB'), 'cc', (0, 'CC')),\n",
       " ((3, 'VB'), 'nsubj', (1, 'PRP')),\n",
       " ((3, 'VB'), 'aux', (2, 'MD')),\n",
       " ((3, 'VB'), 'dep', (5, 'VB')),\n",
       " ((3, 'VB'), 'ccomp', (9, 'VBP')),\n",
       " ((9, 'VBP'), 'mark', (7, 'IN')),\n",
       " ((9, 'VBP'), 'nsubj', (8, 'PRP')),\n",
       " ((9, 'VBP'), 'xcomp', (10, 'JJ'))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- stemmed ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'but'),\n",
       " (1, 'i'),\n",
       " (2, 'must'),\n",
       " (3, 'say'),\n",
       " (4, ''),\n",
       " (5, 'Elizabeth_Bennet'),\n",
       " (6, ''),\n",
       " (7, 'that'),\n",
       " (8, 'you'),\n",
       " (9, 'look'),\n",
       " (10, 'nice')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((set(), set()), ({'Elizabeth_Bennet'}, set()))"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features_from_utterance(\"But I must say, Elizabeth_Bennet, that you look nice\", people, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- triples ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((1, 'NNP'), 'compound', (0, 'NNP')),\n",
       " ((1, 'NNP'), 'appos', (3, 'PRP')),\n",
       " ((3, 'PRP'), 'nmod', (7, 'NN')),\n",
       " ((3, 'PRP'), 'acl:relcl', (9, 'VBD')),\n",
       " ((7, 'NN'), 'case', (4, 'IN')),\n",
       " ((7, 'NN'), 'nmod:poss', (5, 'PRP$')),\n",
       " ((7, 'NN'), 'compound', (6, 'NN')),\n",
       " ((9, 'VBD'), 'nsubj', (8, 'WP')),\n",
       " ((9, 'VBD'), 'xcomp', (11, 'RB')),\n",
       " ((11, 'RB'), 'nsubj', (10, 'PRP'))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- stemmed ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'dear'),\n",
       " (1, 'Elizabeth_Bennet'),\n",
       " (2, ''),\n",
       " (3, 'i'),\n",
       " (4, 'like'),\n",
       " (5, 'my'),\n",
       " (6, 'uncl'),\n",
       " (7, 'Mr_Bennet'),\n",
       " (8, 'who'),\n",
       " (9, 'left'),\n",
       " (10, 'me'),\n",
       " (11, 'alon')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mr_Robinson': 'mr_robinson', 'William_Goulding': 'william_goulding', 'Young_Luca': 'young_lucas', 'Captain_Carter': 'captain_carter', 'Mr_Morri': 'mr_morris', 'Miss_Mary_King': 'miss_mary_king', 'Haggerston': 'haggerston', 'Mr_Pratt': 'mr_pratt', 'Miss_Pope': 'miss_pope', 'Mr_Gardiner': 'mr_gardiner', 'Mr_Hurst': 'mr_hurst', 'Old_Mr_Wickham': 'old_mr_wickham', 'Anne_de_Bourgh': 'anne_de_bourgh', 'Mr_Collin': 'mr_collins', 'Mr_Bingley': 'mr_bingley', 'Mr_Bennet': 'mr_bennet', 'Lady_Anne_Darcy': 'lady_anne_darcy', 'Mrs_Hill': 'mrs_hill', 'Mr_Philip': 'mr_philips', 'Miss_Grantley': 'miss_grantley', 'Mrs_Bennet': 'mrs_bennet', 'Miss_Watson': 'miss_watson', 'Mr_Jone': 'mr_jones', 'Louisa_Hurst': 'louisa_hurst', 'Mrs_Reynold': 'mrs_reynolds', 'The_Butler': 'the_butler', 'Mrs_Annesley': 'mrs_annesley', 'Jane_Bennet': 'jane_bennet', 'Mr_Chamberlayne': 'mr_chamberlayne', 'Colonel_Fitzwilliam': 'colonel_fitzwilliam', 'Mr_Denny': 'mr_denny', 'Old_Mr_Darcy': 'old_mr_darcy', 'Caroline_Bingley': 'caroline_bingley', 'Georgiana_Darcy': 'georgiana_darcy', 'Sir_William': 'sir_william', 'Kitty_Bennet': 'kitty_bennet', 'Mary_Bennet': 'mary_bennet', 'Mrs_Jenkinson': 'mrs_jenkinson', 'Lady_Catherine': 'lady_catherine', 'Maria_Luca': 'maria_lucas', 'Mrs_Long': 'mrs_long', 'Lydia_Bennet': 'lydia_bennet', 'Mrs_Gardiner': 'mrs_gardiner', 'Mr_Stone': 'mr_stone', 'Mrs_Philip': 'mrs_philips', 'Dawson': 'dawson', 'Mr_Wickham': 'mr_wickham', 'Charlotte': 'charlotte', 'Mr_Darcy': 'mr_darcy', 'Mrs_Nicholl': 'mrs_nicholls', 'Elizabeth_Bennet': 'elizabeth_bennet', 'Lady_Luca': 'lady_lucas', 'Lady_Metcalfe': 'lady_metcalfe', 'Colonel_Forster': 'colonel_forster'}\n",
      "like\n",
      "my\n",
      "uncl\n",
      "Mr_Bennet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((set(), {'Y5=mr_bennet', 'related(Y5, X, uncle)'}),\n",
       " ({'Elizabeth_Bennet'}, set()))"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features_from_utterance(\"Dear Elizabeth_Bennet, I like my uncle Mr_Bennet who left me alone\", people, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- triples ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((2, 'VB'), 'aux', (0, 'VBP')),\n",
       " ((2, 'VB'), 'nsubj', (1, 'PRP')),\n",
       " ((2, 'VB'), 'discourse', (4, 'UH')),\n",
       " ((2, 'VB'), 'ccomp', (10, 'VBP')),\n",
       " ((9, 'NN'), 'nmod:poss', (7, 'PRP$')),\n",
       " ((9, 'NN'), 'compound', (8, 'NN')),\n",
       " ((10, 'VBP'), 'mark', (6, 'IN')),\n",
       " ((10, 'VBP'), 'nsubj', (9, 'NN')),\n",
       " ((10, 'VBP'), 'advcl', (12, 'VBG')),\n",
       " ((10, 'VBP'), 'cc', (16, 'CC')),\n",
       " ((10, 'VBP'), 'conj', (24, 'VB')),\n",
       " ((12, 'VBG'), 'mark', (11, 'IN')),\n",
       " ((12, 'VBG'), 'compound:prt', (13, 'RP')),\n",
       " ((12, 'VBG'), 'dobj', (14, 'NNP')),\n",
       " ((19, 'VBP'), 'mark', (17, 'IN')),\n",
       " ((19, 'VBP'), 'nsubj', (18, 'PRP')),\n",
       " ((22, 'NNP'), 'compound', (21, 'NNP')),\n",
       " ((24, 'VB'), 'advcl', (19, 'VBP')),\n",
       " ((24, 'VB'), 'nsubj', (22, 'NNP')),\n",
       " ((24, 'VB'), 'aux', (23, 'MD')),\n",
       " ((24, 'VB'), 'dobj', (25, 'PRP')),\n",
       " ((28, 'NN'), 'nmod:poss', (27, 'PRP$')),\n",
       " ((29, 'VBD'), 'dep', (2, 'VB')),\n",
       " ((29, 'VBD'), 'nsubj', (28, 'NN')),\n",
       " ((29, 'VBD'), 'xcomp', (32, 'JJ')),\n",
       " ((32, 'JJ'), 'nsubj', (30, 'PRP')),\n",
       " ((32, 'JJ'), 'advmod', (31, 'RB')),\n",
       " ((32, 'JJ'), 'nmod', (34, 'NNP')),\n",
       " ((34, 'NNP'), 'case', (33, 'IN')),\n",
       " ((34, 'NNP'), 'acl:relcl', (38, 'VB')),\n",
       " ((38, 'VB'), 'nsubj', (36, 'PRP')),\n",
       " ((38, 'VB'), 'aux', (37, 'MD')),\n",
       " ((38, 'VB'), 'nmod', (41, 'NN')),\n",
       " ((38, 'VB'), 'ccomp', (43, 'VB')),\n",
       " ((41, 'NN'), 'case', (39, 'TO')),\n",
       " ((41, 'NN'), 'compound', (40, 'NNP')),\n",
       " ((43, 'VB'), 'mark', (42, 'TO')),\n",
       " ((43, 'VB'), 'dobj', (44, 'JJR')),\n",
       " ((43, 'VB'), 'nmod', (46, 'PRP')),\n",
       " ((43, 'VB'), 'cc', (48, 'CC')),\n",
       " ((43, 'VB'), 'conj', (50, 'VB')),\n",
       " ((46, 'PRP'), 'case', (45, 'IN')),\n",
       " ((50, 'VB'), 'mark', (49, 'TO')),\n",
       " ((50, 'VB'), 'ccomp', (54, 'VBP')),\n",
       " ((53, 'NNP'), 'compound', (52, 'NNP')),\n",
       " ((54, 'VBP'), 'advmod', (51, 'WRB')),\n",
       " ((54, 'VBP'), 'nsubj', (53, 'NNP')),\n",
       " ((54, 'VBP'), 'advmod', (55, 'RB')),\n",
       " ((54, 'VBP'), 'nmod', (57, 'NN')),\n",
       " ((57, 'NN'), 'case', (56, 'IN'))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- stemmed ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'do'),\n",
       " (1, 'you'),\n",
       " (2, 'know'),\n",
       " (3, ''),\n",
       " (4, 'mama'),\n",
       " (5, ''),\n",
       " (6, 'that'),\n",
       " (7, 'my'),\n",
       " (8, 'uncl'),\n",
       " (9, 'Mr_Philip'),\n",
       " (10, 'talk'),\n",
       " (11, 'of'),\n",
       " (12, 'turn'),\n",
       " (13, 'away'),\n",
       " (14, 'richard'),\n",
       " (15, ''),\n",
       " (16, 'and'),\n",
       " (17, 'if'),\n",
       " (18, 'he'),\n",
       " (19, 'doe'),\n",
       " (20, ''),\n",
       " (21, 'colonel'),\n",
       " (22, 'forster'),\n",
       " (23, 'will'),\n",
       " (24, 'hire'),\n",
       " (25, 'him'),\n",
       " (26, ''),\n",
       " (27, 'my'),\n",
       " (28, 'aunt'),\n",
       " (29, 'told'),\n",
       " (30, 'me'),\n",
       " (31, 'so'),\n",
       " (32, 'herself'),\n",
       " (33, 'on'),\n",
       " (34, 'saturday'),\n",
       " (35, ''),\n",
       " (36, 'i'),\n",
       " (37, 'shall'),\n",
       " (38, 'walk'),\n",
       " (39, 'to'),\n",
       " (40, 'meryton'),\n",
       " (41, 'to-morrow'),\n",
       " (42, 'to'),\n",
       " (43, 'hear'),\n",
       " (44, 'more'),\n",
       " (45, 'about'),\n",
       " (46, 'it'),\n",
       " (47, ''),\n",
       " (48, 'and'),\n",
       " (49, 'to'),\n",
       " (50, 'ask'),\n",
       " (51, 'when'),\n",
       " (52, 'mr.'),\n",
       " (53, 'denni'),\n",
       " (54, 'come'),\n",
       " (55, 'back'),\n",
       " (56, 'from'),\n",
       " (57, 'town')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mr_Robinson': 'mr_robinson', 'William_Goulding': 'william_goulding', 'Young_Luca': 'young_lucas', 'Captain_Carter': 'captain_carter', 'Mr_Morri': 'mr_morris', 'Miss_Mary_King': 'miss_mary_king', 'Haggerston': 'haggerston', 'Mr_Pratt': 'mr_pratt', 'Miss_Pope': 'miss_pope', 'Mr_Gardiner': 'mr_gardiner', 'Mr_Hurst': 'mr_hurst', 'Old_Mr_Wickham': 'old_mr_wickham', 'Anne_de_Bourgh': 'anne_de_bourgh', 'Mr_Collin': 'mr_collins', 'Mr_Bingley': 'mr_bingley', 'Mr_Bennet': 'mr_bennet', 'Lady_Anne_Darcy': 'lady_anne_darcy', 'Mrs_Hill': 'mrs_hill', 'Mr_Philip': 'mr_philips', 'Miss_Grantley': 'miss_grantley', 'Mrs_Bennet': 'mrs_bennet', 'Miss_Watson': 'miss_watson', 'Mr_Jone': 'mr_jones', 'Louisa_Hurst': 'louisa_hurst', 'Mrs_Reynold': 'mrs_reynolds', 'The_Butler': 'the_butler', 'Mrs_Annesley': 'mrs_annesley', 'Jane_Bennet': 'jane_bennet', 'Mr_Chamberlayne': 'mr_chamberlayne', 'Colonel_Fitzwilliam': 'colonel_fitzwilliam', 'Mr_Denny': 'mr_denny', 'Old_Mr_Darcy': 'old_mr_darcy', 'Caroline_Bingley': 'caroline_bingley', 'Georgiana_Darcy': 'georgiana_darcy', 'Sir_William': 'sir_william', 'Kitty_Bennet': 'kitty_bennet', 'Mary_Bennet': 'mary_bennet', 'Mrs_Jenkinson': 'mrs_jenkinson', 'Lady_Catherine': 'lady_catherine', 'Maria_Luca': 'maria_lucas', 'Mrs_Long': 'mrs_long', 'Lydia_Bennet': 'lydia_bennet', 'Mrs_Gardiner': 'mrs_gardiner', 'Mr_Stone': 'mr_stone', 'Mrs_Philip': 'mrs_philips', 'Dawson': 'dawson', 'Mr_Wickham': 'mr_wickham', 'Charlotte': 'charlotte', 'Mr_Darcy': 'mr_darcy', 'Mrs_Nicholl': 'mrs_nicholls', 'Elizabeth_Bennet': 'elizabeth_bennet', 'Lady_Luca': 'lady_lucas', 'Lady_Metcalfe': 'lady_metcalfe', 'Colonel_Forster': 'colonel_forster'}\n",
      "my\n",
      "aunt\n",
      "{'Mr_Robinson': 'mr_robinson', 'William_Goulding': 'william_goulding', 'Young_Luca': 'young_lucas', 'Captain_Carter': 'captain_carter', 'Mr_Morri': 'mr_morris', 'Miss_Mary_King': 'miss_mary_king', 'Haggerston': 'haggerston', 'Mr_Pratt': 'mr_pratt', 'Miss_Pope': 'miss_pope', 'Mr_Gardiner': 'mr_gardiner', 'Mr_Hurst': 'mr_hurst', 'Old_Mr_Wickham': 'old_mr_wickham', 'Anne_de_Bourgh': 'anne_de_bourgh', 'Mr_Collin': 'mr_collins', 'Mr_Bingley': 'mr_bingley', 'Mr_Bennet': 'mr_bennet', 'Lady_Anne_Darcy': 'lady_anne_darcy', 'Mrs_Hill': 'mrs_hill', 'Mr_Philip': 'mr_philips', 'Miss_Grantley': 'miss_grantley', 'Mrs_Bennet': 'mrs_bennet', 'Miss_Watson': 'miss_watson', 'Mr_Jone': 'mr_jones', 'Louisa_Hurst': 'louisa_hurst', 'Mrs_Reynold': 'mrs_reynolds', 'The_Butler': 'the_butler', 'Mrs_Annesley': 'mrs_annesley', 'Jane_Bennet': 'jane_bennet', 'Mr_Chamberlayne': 'mr_chamberlayne', 'Colonel_Fitzwilliam': 'colonel_fitzwilliam', 'Mr_Denny': 'mr_denny', 'Old_Mr_Darcy': 'old_mr_darcy', 'Caroline_Bingley': 'caroline_bingley', 'Georgiana_Darcy': 'georgiana_darcy', 'Sir_William': 'sir_william', 'Kitty_Bennet': 'kitty_bennet', 'Mary_Bennet': 'mary_bennet', 'Mrs_Jenkinson': 'mrs_jenkinson', 'Lady_Catherine': 'lady_catherine', 'Maria_Luca': 'maria_lucas', 'Mrs_Long': 'mrs_long', 'Lydia_Bennet': 'lydia_bennet', 'Mrs_Gardiner': 'mrs_gardiner', 'Mr_Stone': 'mr_stone', 'Mrs_Philip': 'mrs_philips', 'Dawson': 'dawson', 'Mr_Wickham': 'mr_wickham', 'Charlotte': 'charlotte', 'Mr_Darcy': 'mr_darcy', 'Mrs_Nicholl': 'mrs_nicholls', 'Elizabeth_Bennet': 'elizabeth_bennet', 'Lady_Luca': 'lady_lucas', 'Lady_Metcalfe': 'lady_metcalfe', 'Colonel_Forster': 'colonel_forster'}\n",
      "my\n",
      "uncl\n",
      "Mr_Philip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((set(),\n",
       "  {'Y39=mr_philips', 'related(Y27, X, aunt)', 'related(Y39, X, uncle)'}),\n",
       " (set(), set()))"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features_from_utterance(\"Do you know, Mama, that my uncle Mr_Philips talks of turning away Richard, and if he does, Colonel Forster will hire him. My aunt told me so herself on Saturday.  I shall walk to Meryton to-morrow to hear more about it, and to ask when Mr. Denny comes back from town.\", people, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_triples(root, tree):\n",
    "    for dep, child_addresses in root['deps'].items():\n",
    "        for child_address in child_addresses:\n",
    "            child = tree.get_by_address(child_address)\n",
    "            yield (root['address']-1, root['ctag']), dep, (child_address-1, child['ctag'])\n",
    "            yield from custom_triples(child, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 'VBD'), 'dobj', (3, 'NN')),\n",
       " ((3, 'NN'), 'nmod:poss', (2, 'PRP$')),\n",
       " ((1, 'VBD'), 'nsubj', (0, 'NNP'))]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(custom_triples(tree.root, tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': 8,\n",
       " 'ctag': 'CC',\n",
       " 'deps': defaultdict(list, {}),\n",
       " 'feats': '_',\n",
       " 'head': 4,\n",
       " 'lemma': '_',\n",
       " 'rel': 'cc',\n",
       " 'tag': 'CC',\n",
       " 'word': 'and'}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.get_by_address(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('sparkled', 'VBD'), 'nsubj', ('eyes', 'NNS')),\n",
       " (('eyes', 'NNS'), 'nmod:poss', ('Mrs_Bennet', 'NNP')),\n",
       " (('Mrs_Bennet', 'NNP'), 'case', (\"'s\", 'POS')),\n",
       " (('sparkled', 'VBD'), 'nmod', ('pleasure', 'NN')),\n",
       " (('pleasure', 'NN'), 'case', ('with', 'IN')),\n",
       " (('sparkled', 'VBD'), 'cc', ('and', 'CC')),\n",
       " (('sparkled', 'VBD'), 'conj', ('calling', 'VBG')),\n",
       " (('calling', 'VBG'), 'nsubj', ('she', 'PRP')),\n",
       " (('calling', 'VBG'), 'aux', ('was', 'VBD')),\n",
       " (('calling', 'VBG'), 'advmod', ('eagerly', 'RB')),\n",
       " (('calling', 'VBG'), 'compound:prt', ('out', 'RP')),\n",
       " (('calling', 'VBG'), 'advcl', ('read', 'VBD')),\n",
       " (('read', 'VBD'), 'mark', ('while', 'IN')),\n",
       " (('read', 'VBD'), 'nsubj', ('daughter', 'NN')),\n",
       " (('daughter', 'NN'), 'nmod:poss', ('her', 'PRP$'))]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tree.triples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('3', 'VBD'), 'nsubj', ('2', 'NNS')),\n",
       " (('2', 'NNS'), 'nmod:poss', ('0', 'NNP')),\n",
       " (('0', 'NNP'), 'case', ('1', 'POS')),\n",
       " (('3', 'VBD'), 'advcl', ('9', 'VBD')),\n",
       " (('9', 'VBD'), 'mark', ('4', 'IN')),\n",
       " (('9', 'VBD'), 'nsubj', ('5', 'NN')),\n",
       " (('5', 'NN'), 'cc', ('7', 'CC')),\n",
       " (('5', 'NN'), 'conj', ('8', 'PRP')),\n",
       " (('9', 'VBD'), 'xcomp', ('11', 'VBG')),\n",
       " (('11', 'VBG'), 'advmod', ('10', 'RB')),\n",
       " (('11', 'VBG'), 'compound:prt', ('12', 'RP')),\n",
       " (('11', 'VBG'), 'nmod', ('17', 'NN')),\n",
       " (('17', 'NN'), 'case', ('14', 'IN')),\n",
       " (('17', 'NN'), 'nmod:poss', ('15', 'PRP$')),\n",
       " (('17', 'NN'), 'compound', ('16', 'NN'))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, (1, 'mrs_bennet')),\n",
       " (1, (0, \"'s\")),\n",
       " (2, (4, 'eye')),\n",
       " (3, (0, 'sparkl')),\n",
       " (4, (1, 'with')),\n",
       " (5, (4, 'pleasur')),\n",
       " (6, (0, ',')),\n",
       " (7, (0, 'and')),\n",
       " (8, (1, 'she')),\n",
       " (9, (1, 'was')),\n",
       " (10, (2, 'eager')),\n",
       " (11, (1, 'call')),\n",
       " (12, (2, 'out')),\n",
       " (13, (0, ',')),\n",
       " (14, (0, 'while')),\n",
       " (15, (0, 'her')),\n",
       " (16, (1, 'daughter')),\n",
       " (17, (3, 'read')),\n",
       " (18, (0, ','))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, (2, 'mrs_bennet')),\n",
       " (1, (0, \"'s\")),\n",
       " (2, (2, 'eye')),\n",
       " (3, (0, 'sparkl')),\n",
       " (4, (1, 'with')),\n",
       " (5, (2, 'pleasur')),\n",
       " (6, (0, ',')),\n",
       " (7, (0, 'and')),\n",
       " (8, (0, 'she')),\n",
       " (9, (1, 'was')),\n",
       " (10, (2, 'eager')),\n",
       " (11, (1, 'call')),\n",
       " (12, (2, 'out')),\n",
       " (13, (0, ',')),\n",
       " (14, (0, 'while')),\n",
       " (15, (2, 'her')),\n",
       " (16, (1, 'daughter')),\n",
       " (17, (4, 'read')),\n",
       " (18, (0, ','))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pleasur {'fiancee': 'married', 'son': 'son', 'lady': 'wife', 'aunt': 'aunt', 'husband': 'husband', 'sister': 'sister', 'father': 'father', 'wife': 'wife', 'cousin': 'cousin', 'mother': 'mother', 'daughter': 'daughter', 'uncle': 'uncle'} False\n",
      "read {'fiancee': 'married', 'son': 'son', 'lady': 'wife', 'aunt': 'aunt', 'husband': 'husband', 'sister': 'sister', 'father': 'father', 'wife': 'wife', 'cousin': 'cousin', 'mother': 'mother', 'daughter': 'daughter', 'uncle': 'uncle'} False\n",
      "None None None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['F', None, None], [None, None, None])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features_from_text(\"Mrs_Bennet's eyes sparkled with pleasure, and she was eagerly calling out, while her daughter read,\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(t[2][0]) for t in parser_nsubj_triples if t[0][1] == 'VBN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"daughter\" in true_roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
